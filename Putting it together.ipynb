{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cca7508a-ea17-464a-865e-2517f0f6a386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Mar 13 23:24:19 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.86.01              Driver Version: 536.67       CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4070        On  | 00000000:24:00.0  On |                  N/A |\n",
      "|  0%   36C    P8               9W / 200W |   5793MiB / 12282MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A       145      C   /ollama                                   N/A      |\n",
      "|    0   N/A  N/A       364      G   /Xwayland                                 N/A      |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66f4b8c8-773d-4858-b755-c9a35804c4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! mkdir soundbites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67da8c03-8d03-4eb2-9a30-50062edf7084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44dd5966-f1d5-40f2-a271-42e0affe2c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import gradio as gr\n",
    "import IPython\n",
    "\n",
    "from TTS.api import TTS\n",
    "from pprint import pprint\n",
    "from IPython.display import Audio\n",
    "from langchain_community.llms import Ollama\n",
    "from optimum.bettertransformer import BetterTransformer\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.callbacks.base import BaseCallbackHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1426e32a-b929-4636-87d1-164c5acf1055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.5.2 (SDL 2.28.2, Python 3.10.12)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import pygame\n",
    "pygame.mixer.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b411545-db93-4cc7-a069-6284f7fb35c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > tts_models/en/vctk/vits is already downloaded.\n",
      " > Using model: vits\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:0\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:None\n",
      " | > fft_size:1024\n",
      " | > power:None\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:None\n",
      " | > signal_norm:None\n",
      " | > symmetric_norm:None\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:None\n",
      " | > pitch_fmin:None\n",
      " | > pitch_fmax:None\n",
      " | > spec_gain:20.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:1.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:False\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:10\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > initialization of speaker-embedding layers.\n"
     ]
    }
   ],
   "source": [
    "tts = TTS(\"tts_models/en/vctk/vits\").to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f650bbe-8079-46dc-818a-2308fe4729dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wav = tts.tts(text=\"I'm just an AI, I don't have feelings or emotions like humans do, so I can't experience the world in the same way that you do. However, I'm here to help answer any questions you may have, provide information, and assist you in any way I can. Is there something specific you would like to know or discuss?\", speaker=tts.speakers[2]) #, speaker_wav=\"audio/scarlett_johanson.wav\", language=\"en\")\n",
    "# Audio(np.array(wav), rate=20000, autoplay=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d3fe10-4882-45c5-8541-8f020a53c8f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5787d671-55ce-487b-a59b-ce6cfd102bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm = Ollama( model=\"openhermes\", callback_manager=CallbackManager([StreamingStdOutCallbackHandler()]), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58d81f4c-091f-438b-b83e-3e44cf4e63f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyStreamingCallback(BaseCallbackHandler):\n",
    "    def __init__(self):\n",
    "        self.content = \"\"\n",
    "        \n",
    "    def on_llm_new_token(self, token: str, **kwargs):\n",
    "        self.content += token\n",
    "        if self.content.strip()[-1] in ['.', '?', '!', ':']:\n",
    "            wav = tts.tts(self.content, speaker=tts.speakers[2], verbose=False)\n",
    "            IPython.display.display(Audio(np.array(wav), rate=20000))\n",
    "            print(self.content)\n",
    "            self.content = \"\"\n",
    "            sleep(len(wav) / 20000)\n",
    "\n",
    "handler = MyStreamingCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59b37d2d-108e-4633-9201-cc383b67844f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyStreamingCallback(BaseCallbackHandler):\n",
    "    def __init__(self):\n",
    "        self.content = \"\"\n",
    "        \n",
    "    def on_llm_new_token(self, token: str, **kwargs):\n",
    "        self.content += token\n",
    "        if self.content.strip()[-1] in ['.', '?', '!', ':']:\n",
    "            wav = tts.tts(self.content, speaker=tts.speakers[2], verbose=False)\n",
    "            filename = \"soundbites/\"+ self.content[:12] + \".wav\"\n",
    "            tts.tts_to_file(text=self.content, speaker=tts.speakers[2], file_path=filename)\n",
    "            \n",
    "            if pygame.mixer.music.get_busy() == True:\n",
    "                pygame.mixer.music.queue(filename)\n",
    "            else:\n",
    "                pygame.mixer.music.load(filename)\n",
    "                pygame.mixer.music.play()\n",
    "            print(self.content)\n",
    "            self.content = \"\"\n",
    "\n",
    "handler = MyStreamingCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eecd59db-174b-46ef-9dd9-8535b9412fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"soundbites/ However, I'.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "661039a0-5baa-4120-9333-0866b8e23dd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pygame.mixer.music.get_busy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28d98dab-71ef-4cef-bfc1-10a76943bc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pygame.mixer.music.load(filename)\n",
    "pygame.mixer.music.play()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8b56b42-7276-423d-a51b-7bb63a581f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm2 = Ollama(\n",
    "    model=\"openhermes\",\n",
    "    callbacks=[handler],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89ee7369-5fa7-4bbd-862e-435b9ef019e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Text splitted to sentences.\n",
      "['Hello!']\n",
      " > Processing time: 1.103081464767456\n",
      " > Real-time factor: 1.0549508283363291\n",
      " > Text splitted to sentences.\n",
      "['Hello!']\n",
      " > Processing time: 0.25739169120788574\n",
      " > Real-time factor: 0.2408132548851782\n",
      "Hello!\n",
      " > Text splitted to sentences.\n",
      "[\"I'm a chatbot, so I don't really have emotions, but I'm here to assist and engage with you.\"]\n",
      " > Processing time: 0.40482592582702637\n",
      " > Real-time factor: 0.08503288051064939\n",
      " > Text splitted to sentences.\n",
      "[\"I'm a chatbot, so I don't really have emotions, but I'm here to assist and engage with you.\"]\n",
      " > Processing time: 0.1308269500732422\n",
      " > Real-time factor: 0.028308351478989933\n",
      " I'm a chatbot, so I don't really have emotions, but I'm here to assist and engage with you.\n",
      " > Text splitted to sentences.\n",
      "['How can I help you today?']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:langchain_core.callbacks.manager:Error in MyStreamingCallback.on_llm_new_token callback: IndexError('string index out of range')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Processing time: 0.14438962936401367\n",
      " > Real-time factor: 0.09008010772624778\n",
      " > Text splitted to sentences.\n",
      "['How can I help you today?']\n",
      " > Processing time: 0.12740182876586914\n",
      " > Real-time factor: 0.08006185374736134\n",
      " How can I help you today?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Hello! I'm a chatbot, so I don't really have emotions, but I'm here to assist and engage with you. How can I help you today?\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm2.invoke(\"Hey how are you doing?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a248ff78-8898-4de4-a3b9-9a5da6543504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm(\"How are you feeling today?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "322f89bd-126e-429a-a161-49b9f2ea589d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "whisper_model_id = \"distil-whisper/distil-medium.en\"\n",
    "\n",
    "whisper = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    whisper_model_id, torch_dtype=torch.float16, low_cpu_mem_usage=True, use_safetensors=True# , use_flash_attention_2=True\n",
    ")\n",
    "whisper.to(\"cuda\")\n",
    "# model = model.to_bettertransformer() # we are using optimum BetterTransformer since Flash Attention 2 isn't supported on Colab\n",
    "processor = AutoProcessor.from_pretrained(whisper_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b1ad958f-a079-4329-a4dc-a6cee5917854",
   "metadata": {},
   "outputs": [],
   "source": [
    "asr_pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=whisper,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    max_new_tokens=128,\n",
    "    chunk_length_s=15, #long form transcription\n",
    "    batch_size=16,\n",
    "    torch_dtype=torch.float16,\n",
    "    device='cuda',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f52c9735-db35-421f-937f-7f9072c3d649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ismail/envs/hym/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/home/ismail/envs/hym/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I apologize, but I'm a large language model, I cannot provide you with a \"<<SYS>><</SYS>>\" command as it is not a valid or recognized command in any operating system. It appears to be a syntax error or a made-up command. Can I help you with anything else?\n",
      "The meaning of"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ismail/envs/hym/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " life is a complex and philosophical question that has been debated throughout human history. There are many different perspectives on what gives life meaning, and there is no one definitive answer. However, here are some possible ways to approach the question:\n",
      "\n",
      "1. Religious or spiritual beliefs: Many people believe that the purpose of life is to fulfill a divine or spiritual purpose, such as following the teachings of a particular religion or fulfilling a divine plan.\n",
      "2. Personal growth and development: Some people believe that the meaning of life is to learn, grow, and develop as individuals, and to become the best version of themselves.\n",
      "3. Relationships and connections: Others believe that the meaning of life is found in the relationships and connections we have with others, such as family, friends, and community.\n",
      "4. Contribution and legacy: Some people believe that the meaning of life is to make a positive impact on the world and to leave a lasting legacy.\n",
      "5. Experience and enjoyment: Some people believe that the meaning of life is to experience and enjoy the world around us, and to find happiness and fulfillment in our daily lives.\n",
      "6. Self-actualization: According to psychologist Abraham Maslow, self-actualization is the highest human need, which involves realizing one's full potential and becoming the best version of oneself.\n",
      "7. Personal values and beliefs: The meaning of life can also be influenced by personal values and beliefs, such as what is important to us, what we stand for, and what gives our life purpose and direction.\n",
      "8. Cultural and societal influences: The meaning of life can also be shaped by cultural and societal influences, such as the values and beliefs of our upbringing, the culture we belong to, and the social norms and expectations of our community.\n",
      "9. Existentialism: Some people believe that life has no inherent meaning, and that it is up to each individual to create their own purpose and meaning in life.\n",
      "10. Happiness and fulfillment: Many people believe that the meaning of life is to find happiness and fulfillment, whether through personal achievements, relationships, or contributions to society.\n",
      "\n",
      "Ultimately, the meaning of life is a deeply personal and subjective question, and each person must find their own answer based on their own beliefs, values, and experiences.Keyboard interruption in main thread... closing server.\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import numpy as np\n",
    "\n",
    "def transcribe(filepath):\n",
    "    output = asr_pipe(\n",
    "        filepath,\n",
    "    )\n",
    "    return output[\"text\"]\n",
    "\n",
    "\n",
    "def transcribe_streaming(stream, new_chunk):\n",
    "    sr, y = new_chunk\n",
    "    y = y.astype(np.float32)\n",
    "    y /= np.max(np.abs(y))\n",
    "\n",
    "    if stream is not None:\n",
    "        stream = np.concatenate([stream, y])\n",
    "    else:\n",
    "        stream = y\n",
    "\n",
    "    transcribed_stream = asr_pipe({\"sampling_rate\": sr, \"raw\": stream})[\"text\"]\n",
    "    if transcribed_stream.strip().endswith('?') and len(transcribed_stream) > 30:\n",
    "        for w in llm(transcribed_stream):\n",
    "            \n",
    "    \n",
    "    return stream, transcribed_stream\n",
    "\n",
    "demo = gr.Blocks()\n",
    "\n",
    "mic_transcribe = gr.Interface(\n",
    "    title='My Audio Transcription App Powered by Distill Whisper',\n",
    "    description=\"Start recording\",\n",
    "    fn=transcribe_streaming,\n",
    "    inputs=[\"state\", gr.Audio(sources=\"microphone\", streaming=True)],\n",
    "    outputs=[\"state\", \"text\"],\n",
    "    live=True,\n",
    ")\n",
    "\n",
    "\n",
    "file_transcribe = gr.Interface(\n",
    "    title='My Audio Transcription App Powered by Distill Whisper',\n",
    "    description=\"Upload an audio file\",\n",
    "    fn=transcribe,\n",
    "    inputs=gr.Audio(sources=\"upload\", type=\"filepath\"),\n",
    "    outputs=gr.Textbox(),\n",
    ")\n",
    "\n",
    "\n",
    "gr.close_all()\n",
    "\n",
    "with demo:\n",
    "    gr.TabbedInterface(\n",
    "        [mic_transcribe, file_transcribe],\n",
    "        [\"Transcribe Microphone\",  \"Transcribe Audio File\", ],\n",
    "    )\n",
    "\n",
    "demo.launch(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1e72f3-dd87-4568-bb5b-aadd0777f1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.float16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521d9f86-bd20-4ffc-b6fe-fe5417452d60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
